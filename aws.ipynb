{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- How we can dockerize the ML or DL model\n",
    "\n",
    "- How we can deploy the docker image on AWS\n",
    "\n",
    "- Learn about useful docker commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Docker? \n",
    "\n",
    "- Docker is a container management service\n",
    "\n",
    "- The keywords of Docker are develop, ship and run anywhere\n",
    "\n",
    "-  It provides tools for simplifying DevOps by enabling developers to create templates called images that can be used to create lightweight virtual machines called containers, which include their applications and all of their applicationsâ€™ dependencies.\n",
    "\n",
    "## How we can deploy the ML or DL model on cloud (AWS)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step for Dockerize the Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape\n",
      "(28, 28, 1)\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.2636 - acc: 0.9183 - val_loss: 0.0599 - val_acc: 0.9801\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0929 - acc: 0.9723 - val_loss: 0.0422 - val_acc: 0.9861\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0690 - acc: 0.9796 - val_loss: 0.0362 - val_acc: 0.9877\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0560 - acc: 0.9832 - val_loss: 0.0328 - val_acc: 0.9889\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0481 - acc: 0.9854 - val_loss: 0.0302 - val_acc: 0.9898\n",
      "Test loss: 0.030232381611713207\n",
      "Test accuracy: 0.9898\n",
      "M:\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(28, 28, 1)\n",
      "[2.0545217e-10 4.4045403e-09 4.0837971e-08 4.8953228e-07 6.0790657e-11\n",
      " 2.6974056e-10 3.5920363e-13 9.9999928e-01 2.1442772e-09 2.8271577e-07]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Train, Evaluate and Save the DL Model\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('input_shape')\n",
    "print(input_shape)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# # Save the weights\n",
    "# model.save_weights('model_weights.h5')\n",
    "# # Save the model architecture\n",
    "# with open('model_architecture.json', 'w') as f:\n",
    "#     f.write(model.to_json())\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('M:')\n",
    "print(y_test[0])\n",
    "print(x_test[0].shape)\n",
    "x = x_test[0].reshape(1, 28, 28, 1)\n",
    "out = model.predict(x)\n",
    "print(out[0])\n",
    "print(np.argmax(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step for Dockerize the Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a flask API for our DL Model\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from flask_restplus import Api, Resource, fields\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "from werkzeug.datastructures import FileStorage\n",
    "from PIL import Image\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "api = Api(app, version='1.0', title='MNIST Classification', description='CNN for Mnist')\n",
    "ns = api.namespace('Make_School', description='Methods')\n",
    "\n",
    "single_parser = api.parser()\n",
    "single_parser.add_argument('file', location='files',\n",
    "                           type=FileStorage, required=True)\n",
    "\n",
    "model = load_model('my_model.h5')\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "# with open('model_architecture.json', 'r') as f:\n",
    "#     model = model_from_json(f.read())\n",
    "#\n",
    "# # Load weights into the new model\n",
    "# model.load_weights('model_weights.h5')\n",
    "\n",
    "\n",
    "@ns.route('/prediction')\n",
    "class CNNPrediction(Resource):\n",
    "    \"\"\"Uploads your data to the CNN\"\"\"\n",
    "    @api.doc(parser=single_parser, description='Upload an mnist image')\n",
    "    def post(self):\n",
    "        args = single_parser.parse_args()\n",
    "        image_file = args.file\n",
    "        image_file.save('milad.png')\n",
    "        img = Image.open('milad.png')\n",
    "        image_red = img.resize((28, 28))\n",
    "        image = img_to_array(image_red)\n",
    "        print(image.shape)\n",
    "        x = image.reshape(1, 28, 28, 1)\n",
    "        x = x/255\n",
    "        # This is not good, because this code implies that the model will be\n",
    "        # loaded each and every time a new request comes in.\n",
    "        # model = load_model('my_model.h5')\n",
    "        with graph.as_default():\n",
    "            out = model.predict(x)\n",
    "        print(out[0])\n",
    "        print(np.argmax(out[0]))\n",
    "        r = np.argmax(out[0])\n",
    "\n",
    "        return {'prediction': str(r)}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third step for Dockerize the Flask API\n",
    "\n",
    "- Make Dockerfile\n",
    "    - Allows to list a succession of commands describing how to build a container\n",
    "    \n",
    "\n",
    "- All the packges needed in `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dockerfile \n",
    "FROM python:3.6\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "RUN pip install -r requirements.txt\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"flask_example_1.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flask\n",
    "flask_restplus\n",
    "tensorflow\n",
    "keras\n",
    "numpy\n",
    "Pillow\n",
    "werkzeug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth step for Dockerize the Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker build -t flask_keras_docker:latest .\n",
    "    \n",
    "docker run -d -p 8000:8000 flask_keras_docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to push to DockerHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To push:\n",
    "docker login\n",
    "docker tag local-image:tagname reponame:tagname\n",
    "docker push reponame:tagname (docker push 88696316/flask_keras:latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to pull from DockerHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker pull 88696316/flask_keras\n",
    "docker run -p 8000:8000 88696316/flask_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How we can deploy the ML or DL model on cloud (AWS)?\n",
    "\n",
    "We use Amazon Elastic Containers Service (ECS)\n",
    "\n",
    "Lets watch: https://www.youtube.com/watch?v=-Vsuzi4OByY\n",
    "\n",
    "1- `login_command=$(aws ecr get-login --no-include-email --region us-east-1)`\n",
    "\n",
    "2- `docker tag flask_keras_docker:latest 312741836182.dkr.ecr.us-east-1.amazonaws.com/flask-keras-on-fargate-aws:latest`\n",
    "\n",
    "3- `docker push 312741836182.dkr.ecr.us-east-1.amazonaws.com/flask-keras-on-fargate-aws:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit Inbound Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Docker Commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker ps -a, docker ps, docker images\n",
    "docker logs <container_id>\n",
    "docker stop <container_id>, docker kill <container_id>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
